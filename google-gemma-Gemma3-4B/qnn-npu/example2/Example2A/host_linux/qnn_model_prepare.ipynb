{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8bae8a",
   "metadata": {},
   "source": [
    "# QNN Model Prepare on Linux\n",
    "\n",
    "The Qualcomm AI Engine Direct SDK allows clients to run ML models on HTP hardware. The following steps describe how to prepare the Siglip models on Linux platforms for execution on Android and Linux.\n",
    "\n",
    "This document uses the term Qualcomm Neural Network (QNN) and Qualcomm AI Engine Direct SDK interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbc7b3-5232-49e8-b569-9b82febd559d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Qualcomm AI Engine Direct SDK (with Ubuntu Linux support) version 2.31 for veg conversion from onnx to final context binary.\n",
    "2. Qualcomm AI Runtime SDK version 2.40.0 for MHA2SHA\n",
    "3. Ubuntu 22.04 installation with required packages for QNN Tools\n",
    "4. This notebook could be executed with Anaconda or a virtual environment (venv)\n",
    "5. Gemma3-4b VEG `.onnx` files and their corresponding AIMET encodings (generated via AIMET workflow)\n",
    "\n",
    "This work flow assumes that you have generated the Gemma3-4b vision model (siglip) artifacts following the AIMET workflow (example1):\n",
    "\n",
    "- VEG model and its AIMET encodings\n",
    "- `*.raw` file - input data for VEG model\n",
    "- `*.pkl` files per network - numpy object array saved as a Python pickle that contains data that is required as part of the model conversion step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7d4f0",
   "metadata": {},
   "source": [
    "## Install the required python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f886b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet -r ../../example2_env_req.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9395c73",
   "metadata": {},
   "source": [
    "## Set up models and Qualcomm AI Engine Direct SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e54d16",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set up Gemma3-4b siglip VEG models for on-target inference\n",
    "VEG_MODEL = \"/tmp/output_dir/export\"\n",
    "\n",
    "# Set QNN_SDK_ROOT environment variable to the location of Qualcomm AI Engine Directory\n",
    "QNN_SDK_ROOT = '/tmp/qnn' # QNN 2.31\n",
    "QAIRT_SDK_ROOT = '/tmp/qnn'\n",
    "# Create directory where artifacts will be exported\n",
    "EXPORT_DIR = \"./exports\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "print(QNN_SDK_ROOT)\n",
    "\n",
    "# Check path to Gemma3-4b siglip VEG_MODELS and QNN_SDK_ROOT\n",
    "assert os.path.exists(VEG_MODEL) == True, \"VEG_MODEL path does not exist\"\n",
    "assert os.path.exists(QNN_SDK_ROOT) == True, \"QNN_SDK_ROOT path does not exist\"\n",
    "os.environ['QNN_SDK_ROOT'] = QNN_SDK_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utilities.nsptargets import NspTargets\n",
    "\n",
    "# Set up nsp target specification\n",
    "# Android and Linux GEN2 are supported for this notebook\n",
    "nsp_target = NspTargets.Android.GEN2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1a5ea",
   "metadata": {},
   "source": [
    "### Set up environment variables for the Qualcomm AI Direct SDK tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c40d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "workfolder = os.getcwd()\n",
    "sys.path.append(workfolder+'/../G2G')\n",
    "sys.path.append(workfolder+'/../G2G/split_onnx_utils')\n",
    "sys.path.append(workfolder+'/../../')\n",
    "qnn_env = os.environ.copy()\n",
    "qnn_env[\"QNN_SDK_ROOT\"] = QNN_SDK_ROOT\n",
    "qnn_env[\"PYTHONPATH\"] = QNN_SDK_ROOT + \"/benchmarks/QNN/:\" + QNN_SDK_ROOT + \"/lib/python\"\n",
    "qnn_env[\"PATH\"] = QNN_SDK_ROOT + \"/bin/x86_64-linux-clang:\" + qnn_env[\"PATH\"]\n",
    "qnn_env[\"LD_LIBRARY_PATH\"] = QNN_SDK_ROOT + \"/lib/x86_64-linux-clang\"\n",
    "qnn_env[\"HEXAGON_TOOLS_DIR\"] = QNN_SDK_ROOT + \"/bin/x86_64-linux-clang\"\n",
    "os.environ = qnn_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cb4cc",
   "metadata": {},
   "source": [
    "## Convert the model from ONNX representation to QNN representation\n",
    "\n",
    "The Qualcomm AI Engine Direct SDK `qnn-onnx-converter` tool converts a model from ONNX representation to its equivalent QNN representation in `A16W8` precision. The encoding files generated from the AIMET workflow are provided as an input to this step via the `--quantization_overrides model.encodings` option.\n",
    "\n",
    "This step generates a `.cpp` file that represents the model as a series of QNN API calls and a `.bin` file that contains static data that is typically model weights and referenced by the `.cpp` file.\n",
    "\n",
    "This step must be done independently for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16ea5d",
   "metadata": {},
   "source": [
    "### Generate model inputs list for VEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_input_data = os.path.join(VEG_MODEL,\"test_vectors/raw_inputs/pixel_values.raw\")\n",
    "\n",
    "veg_input_file = os.path.join(VEG_MODEL, \"veg_input_list.txt\")\n",
    "\n",
    "with open(veg_input_file, \"w\") as f:\n",
    "    # write to input_list.txt\n",
    "    f.write(\"pixel_values:=\" + veg_input_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9f12e",
   "metadata": {},
   "source": [
    "# MHA2SHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47a94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "mha2sha_root = workfolder+\"/../G2G/MHA2SHA\"\n",
    "g2g_env = os.environ.copy()\n",
    "g2g_env[\"PYTHONPATH\"] = os.pathsep.join([g2g_env.get(\"PYTHONPATH\", \"\"), os.path.join(mha2sha_root, \"src/python\")])\n",
    "g2g_env[\"PATH\"] = os.pathsep.join([g2g_env.get(\"PATH\", \"\"), os.path.join(mha2sha_root, \"bin\")])\n",
    "print(f\"MHA2SHA tool root set to: {mha2sha_root}\")\n",
    "\n",
    "print(g2g_env[\"PYTHONPATH\"])\n",
    "sha_name = \"veg_sha\"\n",
    "sha_folder = \"exports/sha_output\"\n",
    "def thread_g2g():\n",
    "    os.makedirs(sha_folder, exist_ok=True)\n",
    "\n",
    "    sys.path.insert(0, QAIRT_SDK_ROOT + \"/lib/python\")\n",
    "    from qti.aisw.tools.core.utilities.framework.frameworks.onnx.onnx_model import OnnxModel\n",
    "\n",
    "    onnxmodel = OnnxModel.load(\n",
    "        model_path=VEG_MODEL + \"/onnx/siglip.onnx\",\n",
    "        encodings_path=VEG_MODEL + \"/onnx/siglip.encodings\"\n",
    "    )\n",
    "    \n",
    "    # Run mha2sha\n",
    "    onnxmodel.mha2sha_v2()\n",
    "    \n",
    "    # Save output\n",
    "    onnxmodel.export(str(sha_folder), prefix=sha_name)\n",
    "\n",
    "    print(f\"mha2sha-onnx-converter siglip_sha done.\")\n",
    "\n",
    "thread_g2g()\n",
    "print(f\"All mha2sha convert done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892476b",
   "metadata": {},
   "source": [
    "### Convert VEG\n",
    "Expected execution time: 3min ~ 4min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c0206",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "!mkdir -p $EXPORT_DIR/converted_veg\n",
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-onnx-converter\",\n",
    "                  \"-o\", EXPORT_DIR + \"/converted_veg/veg.cpp\",\n",
    "                   \"--input_network\", os.path.join(sha_folder, sha_name + \".onnx\"),\n",
    "                   \"--input_list\", VEG_MODEL + \"/veg_input_list.txt\",\n",
    "                   \"--act_bitwidth\", \"16\",\n",
    "                   \"--bias_bitwidth\", \"32\",\n",
    "                   \"--quantization_overrides\", os.path.join(sha_folder, sha_name + \".encodings\")\n",
    "                 ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=qnn_env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cfc5ab",
   "metadata": {},
   "source": [
    "## QNN model library\n",
    "\n",
    "The  Qualcomm AI Engine Direct SDK `qnn-model-lib-generator` compiles the model `.cpp` and `.bin` files into a shared object library for a specific target. This example generates a shared object library for x86_64-linux target.\n",
    "\n",
    "The inputs to this stage are the `model.cpp` and `model.bin` files generated in the previous step.\n",
    "\n",
    "### Generate the VEG model library\n",
    "Expected execution time: ~5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85264fb5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-model-lib-generator\",\n",
    "                        \"-c\", EXPORT_DIR + \"/converted_veg/veg.cpp\",\n",
    "                        \"-b\", EXPORT_DIR + \"/converted_veg/veg.bin\",\n",
    "                        \"-t\", \"x86_64-linux-clang\",\n",
    "                        \"-o\", EXPORT_DIR + \"/converted_veg\"\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=qnn_env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11140c1",
   "metadata": {},
   "source": [
    "## QNN HTP weight sharing context binary\n",
    "\n",
    "The  Qualcomm AI Engine Direct SDK `qnn-context-binary-generator` tool creates a QNN context binary applicable to the QNN HTP backend. This binary can be deployed to run on a Snapdragon 8 Gen 4 device that runs Android. This step requires the model shared object library from the previous step and the `libQnnHtp.so` library, available in the Qualcomm AI Engine Direct SDK.\n",
    "\n",
    "Provide additional options that pertain to the QNN HTP backend by passing the `libQnnHtpBackendExtensions.so` library that implements extensions for the QNN HTP backend. The library is available in the Qualcomm AI Engine Direct SDK. The library and configurations are provided as a `.json` format as shown below. Documentation on backend extensions and configuraton parameters is available in the Qualcomm AI Engine Direct SDK Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5ecf9-fdeb-44c4-bf67-8c7b4fc39bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create tmp directory for config files\n",
    "CONFIG_DIR = os.path.join(EXPORT_DIR, \"configs\")\n",
    "os.makedirs(CONFIG_DIR, exist_ok=True)\n",
    "\n",
    "# HTP backend extensions config file (htp_backend_extensions.json) example\n",
    "htp_backend_extensions_data = {\"backend_extensions\": {\"shared_library_path\": \"libQnnHtpNetRunExtensions.so\", \"config_file_path\": os.path.join(CONFIG_DIR, \"htp_config.json\")}}\n",
    "soc_id = 88\n",
    "dsp_arch = 'v81'\n",
    "\n",
    "# HTP backend config file (htp_config.json) example\n",
    "htp_backend_config_data = {\n",
    "    \"graphs\": [{\n",
    "        \"vtcm_mb\": 8,\n",
    "        \"graph_names\": [],\n",
    "        \"O\": 3.0,\n",
    "        \"fp16_relaxed_precision\": 0\n",
    "    }],\n",
    "    \"devices\": [{\n",
    "        \"soc_id\": soc_id,\n",
    "        \"dsp_arch\": dsp_arch,\n",
    "        \"cores\": [{\n",
    "            \"core_id\": 0,\n",
    "            \"perf_profile\": \"burst\",\n",
    "            \"rpc_control_latency\": 100\n",
    "        }]\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9386a4a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a path under the models directory for serialized binaries\n",
    "!mkdir -p $EXPORT_DIR/serialized_binaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73210cd5",
   "metadata": {},
   "source": [
    "### Generate the QNN context binary for VEG \n",
    "Expected execution time: ~ 2.5 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e51b4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# write the config files to a temporary location\n",
    "htp_backend_config_data[\"graphs\"][0][\"graph_names\"] = [\"veg\"]\n",
    "with open(os.path.join(CONFIG_DIR, \"htp_backend_extensions.json\"),'w') as f:\n",
    "    f.write(json.dumps(htp_backend_extensions_data, indent=4))\n",
    "with open(os.path.join(CONFIG_DIR, \"htp_config.json\"),'w') as f:\n",
    "    f.write(json.dumps(htp_backend_config_data, indent=4))\n",
    "\n",
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-context-binary-generator\",\n",
    "                             \"--model\", EXPORT_DIR + \"/converted_veg/x86_64-linux-clang/libveg.so\",\n",
    "                             \"--backend\", \"libQnnHtp.so\",\n",
    "                             \"--output_dir\",  EXPORT_DIR + \"/serialized_binaries\",\n",
    "                             \"--binary_file\", \"veg.serialized\",\n",
    "                             \"--config_file\", os.path.join(CONFIG_DIR, \"htp_backend_extensions.json\")\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=qnn_env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-syracuse",
   "metadata": {},
   "source": [
    " \n",
    "Copyright (c) 2024 Qualcomm Technologies, Inc. and/or its subsidiaries."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
